FROM python:3.10-slim

WORKDIR /app

# Install required packages
RUN apt-get update && apt-get install -y git && rm -rf /var/lib/apt/lists/*
RUN pip install torch transformers accelerate fastapi uvicorn

# Add model server script
COPY llama_api.py .

# Download the model on build
RUN python -c "from transformers import AutoTokenizer, AutoModelForCausalLM; \
               AutoTokenizer.from_pretrained('TinyLlama/TinyLlama-1.1B-Chat-v1.0'); \
               AutoModelForCausalLM.from_pretrained('TinyLlama/TinyLlama-1.1B-Chat-v1.0')"

CMD ["uvicorn", "llama_api:app", "--host", "0.0.0.0", "--port", "8001"]
